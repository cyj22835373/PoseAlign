{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48045967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
    "from modules.keypoints import extract_keypoints, group_keypoints\n",
    "from modules.load_state import load_state\n",
    "from modules.pose import Pose, track_poses\n",
    "from val import normalize, pad_width\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd7fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageReader(object):\n",
    "    def __init__(self, file_names):\n",
    "        self.file_names = file_names\n",
    "        self.max_idx = len(file_names)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.idx == self.max_idx:\n",
    "            raise StopIteration\n",
    "        print(\"ImageReader\",self.file_names[self.idx])\n",
    "        img = cv2.imread(self.file_names[self.idx],cv2.IMREAD_COLOR)\n",
    "        #print(img.shape)\n",
    "        if img.size == 0:\n",
    "            raise IOError('Image {} cannot be read'.format(self.file_names[self.idx]))\n",
    "        self.idx = self.idx + 1\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1878cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader(object):\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        try:  # OpenCV needs int to read from webcam\n",
    "            self.file_name = int(file_name)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.cap = cv2.VideoCapture(self.file_name)\n",
    "        if not self.cap.isOpened():\n",
    "            raise IOError('Video {} cannot be opened'.format(self.file_name))\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        was_read, img = self.cap.read()\n",
    "        if not was_read:\n",
    "            raise StopIteration\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b93f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demo(net, image_provider, height_size, cpu, track, smooth,videopath,hFov):\n",
    "    net = net.eval()\n",
    "    if not cpu:\n",
    "        net = net.cuda()\n",
    "\n",
    "    stride = 8\n",
    "    upsample_ratio = 4\n",
    "    num_keypoints = Pose.num_kpts\n",
    "    previous_poses = []\n",
    "    delay = 1\n",
    "    \n",
    "    if type(image_provider)==VideoReader:\n",
    "        image_provider=image_provider.__iter__()\n",
    "        imgw = int(image_provider.cap.get(3))\n",
    "        imgh = int(image_provider.cap.get(4))\n",
    "        fps = image_provider.cap.get(5)\n",
    "        cameraf = imgw/2 /math.tan(hFov/2/180*3.14)\n",
    "        if len(videopath) > 4:\n",
    "            resultVideoPath = videopath[0:len(videopath)-4]+'_result.avi'\n",
    "        else:\n",
    "            resultVideoPath = videopath + '_result.avi'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        print(resultVideoPath,fourcc,fps,imgw,imgh)\n",
    "        out = cv2.VideoWriter(resultVideoPath,fourcc,fps,(imgw,imgh))\n",
    "    elif type(image_provider)==ImageReader:\n",
    "        \n",
    "        imgw = 0\n",
    "        imgh = 0\n",
    "        cameraf = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    for imgindex,img in enumerate(image_provider):\n",
    "        orig_img = img.copy()\n",
    "        if type(image_provider)==ImageReader:\n",
    "            imgw = orig_img.shape[1]\n",
    "            imgh = orig_img.shape[0]\n",
    "            cameraf = imgw/2 /math.tan(hFov/2/180*3.14)\n",
    "        \n",
    "        heatmaps, pafs, scale, pad = infer_fast(net, img, height_size, stride, upsample_ratio, cpu)\n",
    "\n",
    "        total_keypoints_num = 0\n",
    "        all_keypoints_by_type = []\n",
    "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
    "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
    "\n",
    "        pose_entries,all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
    "        for kpt_id in range(all_keypoints.shape[0]):\n",
    "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio) / scale\n",
    "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio) / scale\n",
    "#         for kpt_id in range(all_keypoints.shape[0]):\n",
    "#            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
    "#            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
    "  \n",
    "        current_poses = []\n",
    "        for n in range(len(pose_entries)):\n",
    "            if len(pose_entries[n]) == 0:\n",
    "                continue\n",
    "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
    "            for kpt_id in range(num_keypoints):\n",
    "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
    "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
    "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
    "            #print(pose_keypoints,type(pose_keypoints))\n",
    "            pose = Pose(pose_keypoints, pose_entries[n][18])\n",
    "            current_poses.append(pose)\n",
    "\n",
    "        if track:\n",
    "            track_poses(previous_poses, current_poses, smooth=smooth)\n",
    "            previous_poses = current_poses\n",
    "        for pose in current_poses:\n",
    "            pose.CalDistance(img,cameraf)\n",
    "            pose.CalHeadPos(img,cameraf)\n",
    "            pose.color[:]=[0,255,0]\n",
    "            pose.draw(img)\n",
    "            pose.GetNormPointsPos()\n",
    "            name=\"data/Poses/kh_0\"\n",
    "            strlists = GetPosesDataFromTxt(name,pose.bbox[0],pose.bbox[1],pose.bbox[2],pose.bbox[3])\n",
    "            poseRef = Pose(strlists[0],32.0)\n",
    "            poseRef.color[:]=[255,0,0]\n",
    "            poseRef.draw(img)\n",
    "            print(pose.CmpWithAnotherPose(poseRef))\n",
    "        img = cv2.addWeighted(orig_img, 0.6, img, 0.4, 0)\n",
    "\n",
    "        for pose in current_poses:\n",
    "            cv2.rectangle(img, (pose.bbox[0], pose.bbox[1]),\n",
    "                          (pose.bbox[0] + pose.bbox[2], pose.bbox[1] + pose.bbox[3]), (0, 255, 0))\n",
    "            if track:\n",
    "                cv2.putText(img, 'id: {}'.format(pose.id), (pose.bbox[0], pose.bbox[1] - 16),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255))\n",
    "                cv2.putText(img,'dis:{}'.format(int(pose.headdis)),(pose.bbox[0], pose.bbox[1] - 32),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'headpitch:{}'.format(int(pose.headpitch)),(pose.bbox[0], pose.bbox[1] - 48),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'headroll:{}'.format(int(pose.headroll)),(pose.bbox[0], pose.bbox[1] - 64),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'headyaw:{}'.format(int(pose.headyaw)),(pose.bbox[0], pose.bbox[1] - 80),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'shoyaw:{}'.format(int(pose.shoyaw)),(pose.bbox[0]-80, pose.bbox[1]),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'shoroll:{}'.format(int(pose.shoroll)),(pose.bbox[0]-80, pose.bbox[1] + 16),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'ArmLpitch:{}'.format(int(pose.ArmLpitch)),(pose.bbox[0]-80, pose.bbox[1] + 16*2),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'ArmLyaw:{}'.format(int(pose.ArmLyaw)),(pose.bbox[0]-80, pose.bbox[1] + 16*3),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'ArmRpitch:{}'.format(int(pose.ArmRpitch)),(pose.bbox[0]-80, pose.bbox[1] + 16*4),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'ArmRyaw:{}'.format(int(pose.ArmRyaw)),(pose.bbox[0]-80, pose.bbox[1] + 16*5),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'AArmB2L_L:{}'.format(int(pose.AngArmBig2Little_L)),(pose.bbox[0]-80, pose.bbox[1] + 16*6),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "                cv2.putText(img,'AArmB2L_R:{}'.format(int(pose.AngArmBig2Little_R)),(pose.bbox[0]-80, pose.bbox[1] + 16*7),cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0))\n",
    "        \n",
    "        cv2.imshow('Lightweight Human Pose Estimation Python Demo', img)\n",
    "        if type(image_provider)==VideoReader:\n",
    "            out.write(img)\n",
    "        elif type(image_provider)==ImageReader:\n",
    "            resultImgPath = videopath[imgindex][0:len(videopath)-5]+'_result.png'\n",
    "            fp = open(resultImgPath[0:len(resultImgPath)-4]+\".txt\",\"w+\")\n",
    "            for pose in current_poses:\n",
    "                #print(len(pose.NormPPlist))\n",
    "                for i,p in enumerate(pose.NormPPlist):\n",
    "                    if i==0:\n",
    "                        fp.write(str(format(pose.NormPPlist[i],'.3f'))+\",\")\n",
    "                    else:\n",
    "                        #print(i,p)\n",
    "                        fp.write(str(format(p[0],'.3f'))+\",\" + str(format(p[1],'.3f'))+\",\")\n",
    "                fp.write(\"\\n\")\n",
    "            fp.close()\n",
    "            #print(resultImgPath)\n",
    "            cv2.imwrite(resultImgPath,img)\n",
    "        key = cv2.waitKey(delay)\n",
    "        if key == 27:  # esc\n",
    "            print(\"Exc\")\n",
    "            out.release()\n",
    "            image_provider.cap.release()\n",
    "            return\n",
    "        elif key == 112:  # 'p'\n",
    "            if delay == 1:\n",
    "                delay = 0\n",
    "            else:\n",
    "                delay = 1\n",
    "    if type(image_provider)==VideoReader:\n",
    "        out.release()\n",
    "        image_provider.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f58057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_fast(net, img, net_input_height_size, stride, upsample_ratio, cpu,\n",
    "               pad_value=(0, 0, 0), img_mean=np.array([128, 128, 128], np.float32), img_scale=np.float32(1/256)):\n",
    "    height, width, _ = img.shape\n",
    "    scale = net_input_height_size / height\n",
    "\n",
    "    scaled_img = cv2.resize(img, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "    scaled_img = normalize(scaled_img, img_mean, img_scale)\n",
    "    min_dims = [net_input_height_size, max(scaled_img.shape[1], net_input_height_size)]\n",
    "    padded_img, pad = pad_width(scaled_img, stride, pad_value, min_dims)\n",
    "\n",
    "    tensor_img = torch.from_numpy(padded_img).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    if not cpu:\n",
    "        tensor_img = tensor_img.cuda()\n",
    "\n",
    "    stages_output = net(tensor_img)\n",
    "\n",
    "    stage2_heatmaps = stages_output[-2]\n",
    "    heatmaps = np.transpose(stage2_heatmaps.squeeze().cpu().data.numpy(), (1, 2, 0))\n",
    "    heatmaps = cv2.resize(heatmaps, (0, 0), fx=upsample_ratio, fy=upsample_ratio, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    stage2_pafs = stages_output[-1]\n",
    "    pafs = np.transpose(stage2_pafs.squeeze().cpu().data.numpy(), (1, 2, 0))\n",
    "    pafs = cv2.resize(pafs, (0, 0), fx=upsample_ratio, fy=upsample_ratio, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return heatmaps, pafs, scale, pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec98856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPosesDataFromTxt(txtPath,x,y,w,h):\n",
    "    fp = open(txtPath+\"._result.txt\",'r')\n",
    "    strlists = fp.readlines()\n",
    "    aspRatio = 0.0\n",
    "    PoseDatas = []\n",
    "    PoseData = []\n",
    "    for i,str1list in enumerate(strlists):\n",
    "        \n",
    "        strlist = str1list.split(',')\n",
    "       \n",
    "        for j,p in enumerate(strlist):\n",
    "           \n",
    "            if j == 37:\n",
    "                continue\n",
    "            if j == 0:\n",
    "                aspRatio = float(strlist[i])\n",
    "            elif j%2== 1:\n",
    "                #print(int(float(strlist[i])*w + x),int(float(strlist[i+1])*h + y))\n",
    "                PoseData.append([int(float(strlist[j])*w + x),int(float(strlist[j+1])*h + y)])\n",
    "            #print(PoseData)\n",
    "        PoseDataNP = np.array(PoseData)\n",
    "        #print(PoseDataNP)\n",
    "        PoseDatas.append(PoseDataNP)\n",
    "    fp.close()\n",
    "    return PoseDatas\n",
    "\n",
    "def Get2PVecsAng(a,b):\n",
    "    da = math.sqrt(a[0]*a[0] + a[1]*a[1])\n",
    "    db = math.sqrt(b[0]*b[0] + b[1]*b[1])\n",
    "    a[0]*b[0] + a[1]*b[1]\n",
    "    return math.acos((a[0]*b[0] + a[1]*b[1])/(da*db))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcba90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96524ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PoseEstimationWithMobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95b9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/checkpoint_iter_370000.pth\", map_location='cpu')\n",
    "load_state(net, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97456389",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgname = [\"data/Poses/kh_1.png\"]\n",
    "frame_provider = ImageReader(imgname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6b3de32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageReader data/Poses/kh_1.png\n",
      "([18.027756377319946, 14.035668847618199, 131.30879635424276, 122.00409829181969, 178.0, 101.9803902718557, 132.3782459469833, 206.0218435020908, 85.0, 25.079872407968907, 46.2709412050371, 55.226805085936306, 24.08318915758459, 5.830951894845301, 41.0, 15.524174696260024, 68.11754546370561, 54.00925846556311], 1323.8995379688315)\n"
     ]
    }
   ],
   "source": [
    "run_demo(net,frame_provider, 256, False, 1, 1,imgname,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1ede48",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoname = \"0\" #\"movetest1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c034640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_provider = VideoReader(videoname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84661b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_result.avi 1145656920 30.0 640 480\n",
      "Exc\n"
     ]
    }
   ],
   "source": [
    "run_demo(net,frame_provider, 256, False, 1, 1,videoname,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1280;h=720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d37e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = w/2 - 100;x2 = 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a8c65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4f96341",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = math.atan((x1-w/2)/f)*180/3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53dfccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2 = math.atan((x2-w/2)/f)*180/3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98a60c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.74692948640797 -5.164378589604892 15.911308076012862\n"
     ]
    }
   ],
   "source": [
    "print(theta2,theta1,theta2-theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdca22d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed93a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1,1.73]\n",
    "b = [1,1.73]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d3b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.08926622017251\n"
     ]
    }
   ],
   "source": [
    "print(Get2PVecsAng(a,b)*180/3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc10a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.3035678388537\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.acos(0.1)*180/3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "450f0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取txt并画在图像上，假设知道检测框\n",
    "#step1 读取txt并提取数字数据\n",
    "name=\"data/Poses/kh_0\"\n",
    "strlists = GetPosesDataFromTxt(name,513,145,130,442)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a56cfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取图片验证读取的数据的正确性\n",
    "img=cv2.imread(name + '.png')\n",
    "pose = Pose(strlists[0], 32.0)\n",
    "pose.draw(img)\n",
    "cv2.imwrite(name + '_testresult.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19479fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f13d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
